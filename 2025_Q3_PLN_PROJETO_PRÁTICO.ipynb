{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2025-Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **PROJETO PR√ÅTICO** [LangChain + Grandes Modelos de Linguagem]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "O **PROJETO PR√ÅTICO** deve ser feito utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook armazenado no Google Drive e o link de um reposit√≥rio no GitHub devem ser enviados usando o seguinte formul√°rio:\n",
        "\n",
        "> https://forms.gle/D4gLqP1iGgyn2hbH8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submiss√£o deve ser feita at√© o dia **07/12 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, at√© √†s 23h59. Por favor, lembre-se de dar permiss√£o de ACESSO IRRESTRITO para o professor da disciplina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnIArN0QY-Ek"
      },
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:** Henrique Carvalho Candido ‚Äì 11201811467 \n",
        "**Integrante 02**: Igor Yudi Oshiro ‚Äì 12201811\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbYD2mw8y4CN"
      },
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UlblxFxzDV-"
      },
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AkE6iW0c3o"
      },
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**: OpenAI ‚Äì GPT-4.1 Mini\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documenta√ß√£o oficial**: https://platform.openai.com/docs/models/gpt-4.1-mini\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yExhaebs-nD"
      },
      "source": [
        "### **API (Opcional)**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjJM_qhEZRy6"
      },
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**: Youtube Data API V3 - CommentThreads\n",
        "\n",
        "**Site oficial**: https://developers.google.com/youtube/v3?hl=pt-br\n",
        "\n",
        "**Link para a documenta√ß√£o oficial**: https://developers.google.com/youtube/v3/docs/commentThreads/list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRI√á√ÉO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXTwkiiGs2BV"
      },
      "source": [
        "Implementar um `notebook` no `Google Colab` que fa√ßa uso do framework **`LangChain`** (obrigat√≥rio) e de um **LLM** aplicando, no m√≠nimo, DUAS t√©cnicas de PLN. As t√©cnicas podem ser aplicada em qualquer c√≥rpus obtido a partir de uma **API** ou a partir de uma p√°gina Web.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1iIUZcwnywO7RuF6VEJ8Rx9NDT1cwteyvsnkhYr0NWtU/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes t√©cnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Corre√ß√£o Gramatical\n",
        "*   Classifica√ß√£o de Textos\n",
        "*   An√°lise de Sentimentos\n",
        "*   Detec√ß√£o de Emo√ß√µes\n",
        "*   Extra√ß√£o de Palavras-chave\n",
        "*   Tradu√ß√£o de Textos\n",
        "*   Sumariza√ß√£o de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** √â obrigat√≥rio usar o e-mail da UFABC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWsBYQNtxmum"
      },
      "source": [
        "### **CRIT√âRIOS DE AVALIA√á√ÉO**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iHdx4BXYruQ"
      },
      "source": [
        "Ser√£o considerados como crit√©rios de avalia√ß√£o os seguintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API** ou **P√°gina Web**.\n",
        "\n",
        "* Projeto dispon√≠vel no Github.\n",
        "\n",
        "* Apresenta√ß√£o (5 a 10 minutos).\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhwdrMp123Xx"
      },
      "source": [
        "**IMPORTANTE**: todo o c√≥digo do notebook deve ser executado. C√≥digo sem execu√ß√£o n√£o ser√° considerado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw09lujGvfjc"
      },
      "source": [
        "### **IMPLEMENTA√á√ÉO**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# IMPORTS DO SISTEMA E TERCEIROS\n",
        "# ============================================\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================\n",
        "# GOOGLE API\n",
        "# ============================================\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# ============================================\n",
        "# LANGCHAIN (ATUALIZADO 2025)\n",
        "# ============================================\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ============================================\n",
        "# REPORTLAB PARA GERA√á√ÉO DE PDF\n",
        "# ============================================\n",
        "from reportlab.platypus import (\n",
        "    SimpleDocTemplate,\n",
        "    Paragraph,\n",
        "    Spacer,\n",
        "    Table,\n",
        "    TableStyle,\n",
        "    Image\n",
        ")\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib import colors\n",
        "\n",
        "# ============================================\n",
        "# VISUALIZA√á√ÉO E NUVEM DE PALAVRAS\n",
        "# ============================================\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURA√á√ÉO DAS CHAVES DE API\n",
        "# ============================================================\n",
        "\n",
        "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURA√á√ÉO DO LLM (Groq ‚Äî modelos gratuitos)\n",
        "# ============================================================\n",
        "\n",
        "def get_llm(provider=\"groq\"):\n",
        "    \"\"\"\n",
        "    Retorna o LLM escolhido.\n",
        "    - provider=\"groq\" ‚Üí modelo Groq (padr√£o)\n",
        "    - provider=\"openai\" ‚Üí modelo OpenAI Mini 1\n",
        "    \"\"\"\n",
        "\n",
        "    if provider == \"openai\":\n",
        "        return ChatOpenAI(\n",
        "            model=\"gpt-4.1-mini\",   \n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "    # Groq (padr√£o)\n",
        "    return ChatGroq(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        temperature=0.1\n",
        "    )\n",
        "\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FUN√á√ÉO: Converter emojis em palavras\n",
        "# ============================================================\n",
        "\n",
        "EMOJI_MAP = {\n",
        "    # ALEGRIA / FELICIDADE\n",
        "    \"üòÇ\": \"risada\", \"ü§£\": \"risada\", \"üòÖ\": \"risada nervosa\", \"üòÅ\": \"feliz\",\n",
        "    \"üòÑ\": \"feliz\", \"üòä\": \"feliz\", \"üòÉ\": \"feliz\", \"üôÇ\": \"feliz leve\",\n",
        "    \"üòÜ\": \"muita risada\", \"üòé\": \"confiante\", \"ü§©\": \"empolgado\", \"ü•≥\": \"celebrando\",\n",
        "    \"üò∫\": \"feliz\",\n",
        "\n",
        "    # AMOR / CARINHO\n",
        "    \"üòç\": \"amor\", \"ü•∞\": \"carinho\", \"üòò\": \"beijo\", \"üòó\": \"beijo leve\",\n",
        "    \"üòª\": \"amor\", \"‚ù§Ô∏è\": \"amor\", \"üíì\": \"amor\", \"üíó\": \"amor\",\n",
        "    \"üíñ\": \"amor\", \"üíò\": \"amor\", \"üíù\": \"carinho\", \"üíï\": \"carinho\",\n",
        "    \"üíû\": \"carinho\", \"üíü\": \"afeto\", \"üíå\": \"amor\", \"üíô\": \"amor\",\n",
        "    \"üíö\": \"amor\", \"üíõ\": \"amor\", \"üíú\": \"amor\", \"üß°\": \"amor\",\n",
        "    \"ü©∑\": \"amor\", \"‚ú®\": \"brilho\", \"ü§ó\": \"abra√ßo\",\n",
        "\n",
        "    # TRISTEZA\n",
        "    \"üò¢\": \"triste\", \"üò≠\": \"chorando\", \"ü•∫\": \"suplica\", \"‚òπÔ∏è\": \"triste\",\n",
        "    \"üòû\": \"desapontado\", \"üòî\": \"triste\", \"üòü\": \"preocupado\",\n",
        "\n",
        "    # RAIVA\n",
        "    \"üò°\": \"raiva\", \"üò†\": \"raiva\", \"ü§¨\": \"muita raiva\",\n",
        "\n",
        "    # SURPRESA\n",
        "    \"üò±\": \"surpresa\", \"üòÆ\": \"surpresa\", \"üòØ\": \"surpresa\", \"üò≤\": \"surpresa\",\n",
        "\n",
        "    # MEDO / ANSIEDADE\n",
        "    \"üò®\": \"medo\", \"üò∞\": \"ansiedade\", \"üò•\": \"angustia\", \"ü•π\": \"emo√ß√£o forte\",\n",
        "\n",
        "    # NOJO\n",
        "    \"ü§¢\": \"nojo\", \"ü§Æ\": \"nojo extremo\",\n",
        "\n",
        "    # NEUTRO / PENSATIVO\n",
        "    \"üòê\": \"neutro\", \"üòë\": \"neutro\", \"ü§î\": \"pensativo\", \"ü§®\": \"duvida\",\n",
        "\n",
        "    # M√ÉOS / GESTOS\n",
        "    \"üôè\": \"gratid√£o\", \"üëç\": \"positivo\", \"üëé\": \"negativo\", \"üëè\": \"aplausos\",\n",
        "    \"üôå\": \"celebra√ß√£o\", \"ü§ù\": \"parceria\", \"‚úåÔ∏è\": \"paz\", \"üëå\": \"ok\",\n",
        "    \"ü§≤\": \"oferta\",\n",
        "\n",
        "    # ANIMAIS\n",
        "    \"üê∂\": \"cachorro\", \"üêï\": \"cachorro\", \"üê±\": \"gato\", \"üêà\": \"gato\",\n",
        "    \"üêæ\": \"patinhas\",\n",
        "\n",
        "    # FOGO / FESTA / M√öSICA\n",
        "    \"üî•\": \"incr√≠vel\", \"üéâ\": \"festa\", \"üéä\": \"celebra√ß√£o\", \"üéµ\": \"musica\",\n",
        "    \"üé∂\": \"musica\", \"üé§\": \"microfone\", \"üéß\": \"audio\", \"üéº\": \"melodia\",\n",
        "\n",
        "    # OUTROS\n",
        "    \"üíÄ\": \"chocado\", \"ü§°\": \"palha√ßada\", \"üåü\": \"estrela\", \"‚≠ê\": \"estrela\",\n",
        "    \"üí•\": \"impacto\",\n",
        "}\n",
        "\n",
        "\n",
        "def emoji_to_text(text: str) -> str:\n",
        "    for emoji, word in EMOJI_MAP.items():\n",
        "        text = text.replace(emoji, f\" {word} \")\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PROMPTS ‚Äî Fun√ß√µes de PLN\n",
        "# ============================================================\n",
        "\n",
        "def build_chains(llm_model):\n",
        "\n",
        "    # Sentimento\n",
        "    sentiment_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "                Classifique o sentimento predominante expresso no coment√°rio abaixo,\n",
        "                considerando que se trata de um coment√°rio sobre uma m√∫sica.\n",
        "                Avalie o tom geral da mensagem, a inten√ß√£o emocional do autor e o impacto impl√≠cito,\n",
        "                incluindo poss√≠veis indica√ß√µes dadas por emojis ou express√µes afetivas.\n",
        "\n",
        "                Escolha APENAS uma das tr√™s op√ß√µes:\n",
        "                - positivo   (elogios, carinho, satisfa√ß√£o, emo√ß√£o boa, nostalgia afetiva)\n",
        "                - negativo   (cr√≠ticas, frustra√ß√£o, inc√¥modo, rejei√ß√£o, emo√ß√£o ruim)\n",
        "                - neutro     (informativo, amb√≠guo ou sem carga emocional clara)\n",
        "\n",
        "                Coment√°rio:\n",
        "                {text}\n",
        "\n",
        "                Regra: responda APENAS com uma das palavras acima, sem explica√ß√µes adicionais.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    emotion_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "            Classifique a emo√ß√£o dominante expressa no coment√°rio abaixo.\n",
        "            Considere o contexto de coment√°rios sobre m√∫sicas, incluindo rea√ß√µes √† melodia,\n",
        "            letra, voz, mem√≥ria afetiva, nostalgia e sentimentos sugeridos por emojis\n",
        "            j√° convertidos em texto.\n",
        "\n",
        "            A resposta deve ser EXATAMENTE uma das emo√ß√µes da lista principal:\n",
        "\n",
        "            alegria\n",
        "            amor\n",
        "            nostalgia\n",
        "            saudade\n",
        "            tristeza\n",
        "            melancolia\n",
        "            raiva\n",
        "            surpresa\n",
        "            inspira√ß√£o\n",
        "            reflex√£o\n",
        "            neutro\n",
        "\n",
        "            Regras obrigat√≥rias:\n",
        "            - escolha somente UMA palavra da lista;\n",
        "            - n√£o use frases, justificativas ou varia√ß√µes;\n",
        "            - n√£o invente emo√ß√µes fora da lista.\n",
        "\n",
        "            Coment√°rio:\n",
        "            {text}\n",
        "\n",
        "            Resposta:\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Keywords\n",
        "    keywords_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "            Extraia entre **5 e 10 palavras-chave realmente significativas** do coment√°rio abaixo.\n",
        "\n",
        "            O objetivo √© identificar elementos centrais do coment√°rio, considerando que ele trata de uma m√∫sica. Portanto, priorize palavras relacionadas a:\n",
        "\n",
        "            - emo√ß√µes (ex: nostalgia, alegria, tristeza)\n",
        "            - temas mencionados (ex: saudade, lembran√ßa, supera√ß√£o)\n",
        "            - experi√™ncia pessoal (ex: inf√¢ncia, momento, vida)\n",
        "            - elementos musicais (ex: melodia, voz, letra, ritmo, guitarra)\n",
        "            - aprecia√ß√£o ou cr√≠tica (ex: incr√≠vel, poderoso, marcante)\n",
        "            - impacto afetivo ou sensorial (ex: arrepio, energia, vibe)\n",
        "\n",
        "            ============================================================\n",
        "            REGRAS OBRIGAT√ìRIAS (SIGA √Ä RISCA):\n",
        "            ============================================================\n",
        "\n",
        "            1) N√£o extraia palavras gen√©ricas demais  \n",
        "            (ex.: m√∫sica, v√≠deo, coisa, muito, bom, legal, a√≠).\n",
        "\n",
        "            2) N√ÉO incluir:\n",
        "            - artigos, pronomes ou conectivos (o, a, que, de, com‚Ä¶)\n",
        "            - emojis\n",
        "            - n√∫meros\n",
        "            - repeti√ß√£o da mesma palavra\n",
        "            - trechos longos ou frases inteiras\n",
        "            - palavras sem valor sem√¢ntico real\n",
        "\n",
        "            3) Extraia apenas palavras isoladas (1 palavra cada),  \n",
        "            sempre no **singular**, sem hashtags.\n",
        "\n",
        "            4) As palavras-chave devem capturar O ESSENCIAL do coment√°rio:\n",
        "            ‚Äî emo√ß√µes centrais  \n",
        "            ‚Äî temas mencionados  \n",
        "            ‚Äî experi√™ncia afetiva  \n",
        "            ‚Äî elementos musicais\n",
        "\n",
        "            5) Responda SOMENTE com as palavras-chave,  \n",
        "            separadas por v√≠rgula, sem coment√°rios extras.\n",
        "\n",
        "            ============================================================\n",
        "            Coment√°rio:\n",
        "            {text}\n",
        "\n",
        "            Responda SOMENTE com as palavras-chave (5 a 10 termos):\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Resumo final (para todos os coment√°rios)\n",
        "    summary_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "            Gere um resumo claro, objetivo e bem estruturado sobre o conjunto de coment√°rios abaixo,\n",
        "            considerando especificamente o contexto de coment√°rios sobre m√∫sicas. \n",
        "            Leve em conta que usu√°rios costumam expressar emo√ß√µes intensas, mem√≥rias pessoais,\n",
        "            sensa√ß√µes despertadas pela melodia ou pela letra, identifica√ß√£o com o artista,\n",
        "            e rea√ß√µes afetivas t√≠picas desse ambiente.\n",
        "\n",
        "            Sua an√°lise deve identificar:\n",
        "\n",
        "            - principais opini√µes e percep√ß√µes dos usu√°rios sobre a m√∫sica, letra, melodia, artista ou impacto emocional;\n",
        "            - emo√ß√µes predominantes e padr√µes emocionais recorrentes (ex.: nostalgia, saudade, alegria, como√ß√£o);\n",
        "            - tend√™ncias gerais de sentimento (positivo, negativo ou neutro) relacionadas √† experi√™ncia musical;\n",
        "            - temas centrais mencionados, como lembran√ßas, relacionamentos, fases da vida, performance do artista, qualidade da produ√ß√£o ou significado pessoal;\n",
        "            - contrastes relevantes entre grupos de coment√°rios (ex.: f√£s antigos vs. novos ouvintes, experi√™ncias pessoais diferentes).\n",
        "\n",
        "            Use linguagem direta, s√≠ntese precisa e foco nas informa√ß√µes realmente relevantes.\n",
        "\n",
        "            Texto analisado:\n",
        "            {text}\n",
        "\n",
        "            Retorne UM √öNICO par√°grafo de at√© 10 linhas, sem listas e evitando repeti√ß√µes.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Classifica√ß√£o do contexto (tipo de rela√ß√£o com a m√∫sica)\n",
        "    context_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "            Classifique o COMPORTAMENTO do coment√°rio em rela√ß√£o √† m√∫sica do v√≠deo.\n",
        "\n",
        "            A classifica√ß√£o deve ser EXCLUSIVA ‚Äî escolha apenas UMA op√ß√£o ‚Äî e considerar o foco principal do que a pessoa escreveu.\n",
        "\n",
        "            ======================================================\n",
        "            CATEGORIAS PERMITIDAS (escolha SOMENTE uma):\n",
        "            ======================================================\n",
        "\n",
        "            1) **sobre_a_musica**\n",
        "            Quando o coment√°rio fala diretamente sobre:\n",
        "            - a m√∫sica, letra, melodia, ritmo, harmonia;\n",
        "            - a performance do artista;\n",
        "            - opini√£o, cr√≠tica ou elogio sobre o som;\n",
        "            - produ√ß√£o musical, qualidade do √°udio, clipe.\n",
        "\n",
        "            Exemplos:\n",
        "            - \"Essa m√∫sica √© perfeita!\"\n",
        "            - \"O refr√£o √© muito forte.\"\n",
        "            - \"O vocal dele t√° incr√≠vel.\"\n",
        "\n",
        "            2) **experiencia_pessoal**\n",
        "            Quando o coment√°rio relata uma mem√≥ria, hist√≥ria ou situa√ß√£o da vida relacionada √† m√∫sica.\n",
        "\n",
        "            Exemplos:\n",
        "            - \"Essa m√∫sica marcou minha adolesc√™ncia.\"\n",
        "            - \"Ouvi essa m√∫sica no meu casamento.\"\n",
        "            - \"Me lembra meu pai que j√° faleceu.\"\n",
        "\n",
        "            3) **trecho_de_letra**\n",
        "            Quando o coment√°rio cont√©m um trecho da m√∫sica, mesmo que modificado levemente.\n",
        "            N√£o importa se a pessoa n√£o cita que √© letra ‚Äî identifique pelo conte√∫do.\n",
        "\n",
        "            Exemplos:\n",
        "            - \"I've given up, I'm sick of feeling!\"\n",
        "            - \"Walk on home boy!\"\n",
        "            - \"S√≥ as antigas v√£o lembrar‚Ä¶\"\n",
        "\n",
        "            4) **off_topic**\n",
        "            Quando o coment√°rio N√ÉO tem rela√ß√£o com a m√∫sica.\n",
        "            Inclui:\n",
        "            - memes aleat√≥rios;\n",
        "            - pol√≠tica, religi√£o, futebol;\n",
        "            - conversa paralela com outros usu√°rios;\n",
        "            - perguntas nada a ver;\n",
        "            - emojis sem contexto;\n",
        "            - spam.\n",
        "\n",
        "            Exemplos:\n",
        "            - \"Quem mais veio por causa do TikTok?\"\n",
        "            - \"Brasil 7x1 Alemanha.\"\n",
        "            - \"Algu√©m sabe qual √© o nome do cachorro?\"\n",
        "\n",
        "            ======================================================\n",
        "            REGRAS OBRIGAT√ìRIAS\n",
        "            ======================================================\n",
        "\n",
        "            - Escolha APENAS UMA op√ß√£o.\n",
        "            - N√ÉO explique sua escolha, N√ÉO adicione texto extra.\n",
        "            - Se houver mistura de elementos, escolha o TEMA PRINCIPAL do coment√°rio.\n",
        "            - Se o coment√°rio tiver letra + opini√£o ‚Üí classifique como **trecho_de_letra**.\n",
        "            - Se o coment√°rio for s√≥ emojis:  \n",
        "                - Se forem claramente emocionais ‚Üí classifique como **sobre_a_musica**.  \n",
        "                - Se forem aleat√≥rios ‚Üí **off_topic**.\n",
        "\n",
        "            ======================================================\n",
        "            Coment√°rio a classificar:\n",
        "            {text}\n",
        "\n",
        "            Responda SOMENTE com uma das op√ß√µes:\n",
        "            sobre_a_musica, experiencia_pessoal, trecho_de_letra, off_topic\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    # Detec√ß√£o de idioma (melhorada para contexto de m√∫sica)\n",
        "    language_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "            Identifique o idioma principal do coment√°rio abaixo.\n",
        "\n",
        "            IMPORTANTE:\n",
        "            - Considere que muitos coment√°rios de YouTube sobre m√∫sicas podem conter:\n",
        "                * trechos da letra,\n",
        "                * nomes de artistas,\n",
        "                * palavras repetidas,\n",
        "                * express√µes informais,\n",
        "                * g√≠rias multil√≠ngues,\n",
        "                * emojis.\n",
        "            - Nesses casos, identifique o idioma predominante da frase como um todo.\n",
        "            - Se houver mistura, escolha o idioma da maior parte do texto.\n",
        "\n",
        "            Responda SOMENTE com o c√≥digo ISO-639-1:\n",
        "            - pt, en, es, fr, de, it, etc.\n",
        "\n",
        "            Coment√°rio:\n",
        "            {text}\n",
        "\n",
        "            Responda exclusivamente com o c√≥digo do idioma, sem frases adicionais.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Tradu√ß√£o autom√°tica (especializada para coment√°rios de m√∫sica)\n",
        "    translate_prompt = PromptTemplate(\n",
        "        input_variables=[\"text\", \"lang\"],\n",
        "        template=\"\"\"\n",
        "            Voc√™ receber√° um coment√°rio de YouTube sobre uma m√∫sica, junto com o idioma detectado.\n",
        "\n",
        "            Se o idioma for \"pt\":\n",
        "                - N√ÉO traduza.\n",
        "                - N√ÉO reescreva.\n",
        "                - Retorne o texto exatamente como est√°.\n",
        "\n",
        "            Caso contr√°rio:\n",
        "                - Traduza o coment√°rio para o portugu√™s brasileiro.\n",
        "                - Mantenha o sentido original, o tom emocional e o estilo do autor.\n",
        "                - Preserve:\n",
        "                    * g√≠rias\n",
        "                    * express√µes culturais\n",
        "                    * nomes pr√≥prios\n",
        "                    * termos musicais (chorus, beat, flow, vocals, harmony)\n",
        "                    * trechos de letra de m√∫sica (sem adaptar)\n",
        "                - Se houver palavras de v√°rios idiomas no mesmo coment√°rio,\n",
        "                traduza apenas o que for do idioma detectado como predominante.\n",
        "\n",
        "            Idioma detectado: {lang}\n",
        "            Coment√°rio original:\n",
        "            {text}\n",
        "\n",
        "            Responda somente com o texto final traduzido ou preservado.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"sentiment\": sentiment_prompt | llm_model | parser,\n",
        "        \"emotion\": emotion_prompt | llm_model | parser,\n",
        "        \"keywords\": keywords_prompt | llm_model | parser,\n",
        "        \"summary\": summary_prompt | llm_model | parser,\n",
        "        \"context\": context_prompt | llm_model | parser,\n",
        "        \"language\": language_prompt | llm_model | parser,\n",
        "        \"translate\": translate_prompt | llm_model | parser,\n",
        "    }\n",
        "\n",
        "LLM_MODEL = get_llm(provider=\"openai\")\n",
        "CHAINS = build_chains(LLM_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# COLETA DE COMENT√ÅRIOS DO YOUTUBE\n",
        "# ============================================================\n",
        "\n",
        "def extract_youtube_comments(\n",
        "    video_id: str,\n",
        "    max_comments: int = 50,\n",
        "    order: str = \"relevance\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Coleta coment√°rios de um v√≠deo do YouTube usando a API oficial.\n",
        "\n",
        "    Par√¢metros:\n",
        "    -----------\n",
        "    video_id : str\n",
        "        ID do v√≠deo no YouTube (ex: 'TAqZb52sgpU').\n",
        "    \n",
        "    max_comments : int, opcional (default=50)\n",
        "        Quantidade m√°xima de coment√°rios a serem coletados.\n",
        "        A API retorna at√© 100 por p√°gina, ent√£o a fun√ß√£o pagina automaticamente.\n",
        "\n",
        "    order : str, opcional (default=\"relevance\")\n",
        "        Ordena√ß√£o dos coment√°rios retornados pela API:\n",
        "            - \"relevance\": mais relevantes (padr√£o do YouTube)\n",
        "            - \"time\": mais recentes\n",
        "            - \"rating\": melhores avaliados (likes)\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    comments : list[dict]\n",
        "        Lista de coment√°rios estruturados com:\n",
        "        - ID do coment√°rio\n",
        "        - Autor\n",
        "        - Texto\n",
        "        - Data de publica√ß√£o\n",
        "        - Likes\n",
        "        - URL direto para o coment√°rio\n",
        "        - ID do v√≠deo\n",
        "\n",
        "    order : str\n",
        "        Retorna a ordena√ß√£o usada (permite salvar no PDF para registro).\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializa o cliente da API do YouTube\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=os.getenv(\"YOUTUBE_API_KEY\"))\n",
        "    \n",
        "    comments = []  # Lista final de coment√°rios coletados\n",
        "\n",
        "    # Primeira requisi√ß√£o ‚Äî coleta os primeiros 100 resultados\n",
        "    request = youtube.commentThreads().list(\n",
        "        part=\"snippet\",\n",
        "        videoId=video_id,\n",
        "        textFormat=\"plainText\",\n",
        "        maxResults=100,   # Limite da API por p√°gina\n",
        "        order=order       # Ordena√ß√£o configur√°vel\n",
        "    )\n",
        "\n",
        "    # Executa a requisi√ß√£o inicial\n",
        "    response = request.execute()\n",
        "\n",
        "    # Continua coletando enquanto existir resposta e n√£o atingir o limite\n",
        "    while response and len(comments) < max_comments:\n",
        "\n",
        "        # Percorre cada coment√°rio retornado na p√°gina atual\n",
        "        for item in response.get(\"items\", []):\n",
        "            \n",
        "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
        "\n",
        "            # Cria estrutura de dados padronizada\n",
        "            comments.append({\n",
        "                \"comment_id\": item[\"snippet\"][\"topLevelComment\"][\"id\"],\n",
        "                \"author\": snippet.get(\"authorDisplayName\"),\n",
        "                \"text\": snippet.get(\"textDisplay\", \"\"),\n",
        "                \"published_at\": snippet.get(\"publishedAt\"),\n",
        "                \"like_count\": snippet.get(\"likeCount\", 0),\n",
        "\n",
        "                # Gera link direto para o coment√°rio (YouTube padr√£o)\n",
        "                \"comment_url\": (\n",
        "                    f\"https://www.youtube.com/watch?v={video_id}&lc=\"\n",
        "                    f\"{item['snippet']['topLevelComment']['id']}\"\n",
        "                ),\n",
        "\n",
        "                \"video_id\": video_id,\n",
        "            })\n",
        "\n",
        "            # Interrompe se j√° alcan√ßou o n√∫mero desejado\n",
        "            if len(comments) >= max_comments:\n",
        "                break\n",
        "\n",
        "        # Se n√£o existe pr√≥xima p√°gina, encerra coleta\n",
        "        if \"nextPageToken\" not in response:\n",
        "            break\n",
        "\n",
        "        # Pagina para pr√≥xima requisi√ß√£o\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            textFormat=\"plainText\",\n",
        "            maxResults=100,\n",
        "            pageToken=response[\"nextPageToken\"],\n",
        "            order=order\n",
        "        ).execute()\n",
        "\n",
        "    # Retorna lista completa e ordena√ß√£o usada (para registro no relat√≥rio)\n",
        "    return comments, order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PROCESSAMENTO INDIVIDUAL DE CADA COMENT√ÅRIO\n",
        "# ============================================================\n",
        "\n",
        "def process_comment(text: str):\n",
        "    \"\"\"\n",
        "    Processa um √∫nico coment√°rio do YouTube aplicando toda a cadeia de NLP:\n",
        "    - Expans√£o de emojis em palavras\n",
        "    - Detec√ß√£o de idioma\n",
        "    - Tradu√ß√£o (quando necess√°rio)\n",
        "    - Classifica√ß√£o de sentimento\n",
        "    - Identifica√ß√£o de emo√ß√£o dominante\n",
        "    - Extra√ß√£o de palavras-chave\n",
        "    - Classifica√ß√£o do contexto (tipo de coment√°rio)\n",
        "\n",
        "    Retorna um dicion√°rio padronizado contendo todas essas informa√ß√µes.\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 1) Expans√£o de emojis para palavras √∫teis\n",
        "    # ------------------------------------------\n",
        "    # Exemplo:\n",
        "    # \"This song ‚ù§Ô∏èüî•\" ‚Üí \"This song amor incr√≠vel\"\n",
        "    # Isso melhora muito a an√°lise sem√¢ntica.\n",
        "    text_expanded = emoji_to_text(text)\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 2) Detectar o idioma predominante\n",
        "    # ------------------------------------------\n",
        "    # O LLM identifica idioma considerando g√≠rias,\n",
        "    # trechos de letra, emojis e mistura de idiomas.\n",
        "    lang = CHAINS[\"language\"].invoke({\"text\": text_expanded}).strip().lower()\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 3) Tradu√ß√£o autom√°tica (somente se n√£o for PT)\n",
        "    # ------------------------------------------\n",
        "    # O texto √© traduzido para PT-BR para padronizar toda a an√°lise\n",
        "    # e permitir que sentimento/emocÃß√£o funcionem melhor.\n",
        "    translated = CHAINS[\"translate\"].invoke({\n",
        "        \"text\": text_expanded,\n",
        "        \"lang\": lang\n",
        "    }).strip()\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 4) Classifica√ß√µes de NLP (sentimento, emo√ß√£o, contexto, keywords)\n",
        "    # ------------------------------------------\n",
        "    sentiment = CHAINS[\"sentiment\"].invoke({\"text\": translated}).strip().lower()\n",
        "    emotion = CHAINS[\"emotion\"].invoke({\"text\": translated}).strip().lower()\n",
        "    keywords = CHAINS[\"keywords\"].invoke({\"text\": translated}).strip()\n",
        "    context = CHAINS[\"context\"].invoke({\"text\": translated}).strip().lower()\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # 5) Retorna tudo padronizado\n",
        "    # ------------------------------------------\n",
        "    return {\n",
        "        \"emoji_expanded\": text_expanded,   # texto original expandido com palavras no lugar de emojis\n",
        "        \"language\": lang,                  # idioma detectado (pt, en, es‚Ä¶)\n",
        "        \"translated\": translated,          # coment√°rio traduzido ou preservado em PT\n",
        "        \"sentiment\": sentiment,            # positivo / negativo / neutro\n",
        "        \"emotion\": emotion,                # uma emo√ß√£o dominante (alegria, nostalgia etc.)\n",
        "        \"keywords\": keywords,              # 5‚Äì10 keywords relevantes\n",
        "        \"context\": context                 # sobre_a_musica / letra / experiencia / off_topic\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# AN√ÅLISE COMPLETA DOS COMENT√ÅRIOS (com logs detalhados)\n",
        "# ============================================================\n",
        "\n",
        "def analyze_comments(comments):\n",
        "    \"\"\"\n",
        "    Aplica o pipeline completo de processamento (NLP) para cada coment√°rio coletado.\n",
        "\n",
        "    O pipeline inclui:\n",
        "        - expans√£o de emojis\n",
        "        - detec√ß√£o de idioma\n",
        "        - tradu√ß√£o (quando necess√°rio)\n",
        "        - classifica√ß√£o de sentimento\n",
        "        - identifica√ß√£o de emo√ß√£o dominante\n",
        "        - extra√ß√£o de palavras-chave\n",
        "        - classifica√ß√£o do contexto\n",
        "\n",
        "    Par√¢metros:\n",
        "    -----------\n",
        "    comments : list[dict]\n",
        "        Lista de coment√°rios retornados pela coleta.\n",
        "\n",
        "    Retorno:\n",
        "    --------\n",
        "    list[dict]\n",
        "        Lista de coment√°rios enriquecidos com todas as an√°lises.\n",
        "    \"\"\"\n",
        "\n",
        "    enriched_data = []\n",
        "\n",
        "    print(\"\\n=== INICIANDO AN√ÅLISE DOS COMENT√ÅRIOS ===\\n\")\n",
        "\n",
        "    for idx, c in enumerate(comments, start=1):\n",
        "\n",
        "        # -------------------------------------------------------\n",
        "        # 1) Valida√ß√£o do coment√°rio antes do processamento\n",
        "        # -------------------------------------------------------\n",
        "        if not isinstance(c, dict):\n",
        "            print(f\"‚ö† Ignorado: coment√°rio inv√°lido (n√£o √© dict): {c}\")\n",
        "            continue\n",
        "\n",
        "        if \"text\" not in c or not isinstance(c[\"text\"], str):\n",
        "            print(f\"‚ö† Ignorado: estrutura inesperada ou texto ausente: {c}\")\n",
        "            continue\n",
        "\n",
        "        raw_text = c[\"text\"].strip()\n",
        "        if raw_text == \"\":\n",
        "            print(f\"‚ö† Ignorado: coment√°rio vazio.\")\n",
        "            continue\n",
        "\n",
        "        # -------------------------------------------------------\n",
        "        # 2) Processamento completo (fun√ß√£o NLP)\n",
        "        # -------------------------------------------------------\n",
        "        try:\n",
        "            processed = process_comment(raw_text)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ERRO ao analisar coment√°rio {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # -------------------------------------------------------\n",
        "        # 3) Combina dados originais + dados processados\n",
        "        # -------------------------------------------------------\n",
        "        enriched = {**c, **processed}\n",
        "        enriched_data.append(enriched)\n",
        "\n",
        "        # -------------------------------------------------------\n",
        "        # 4) Logs amig√°veis para acompanhamento\n",
        "        # -------------------------------------------------------\n",
        "        print(f\"[{idx}/{len(comments)}] Coment√°rio analisado:\")\n",
        "        print(f\"Texto original: {raw_text[:120]}\")  # limita para n√£o explodir o log\n",
        "        print(\n",
        "            f\"‚Üí Sentimento: {processed['sentiment']} | \"\n",
        "            f\"Emo√ß√£o: {processed['emotion']} | \"\n",
        "            f\"Contexto: {processed['context']}\"\n",
        "        )\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "    print(\"\\n=== AN√ÅLISE COMPLETA ===\\n\")\n",
        "\n",
        "    return enriched_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# RESUMO FINAL\n",
        "# ============================================================\n",
        "\n",
        "def generate_final_summary(analyzed_comments):\n",
        "    combined = \"\\n\".join([c[\"translated\"] for c in analyzed_comments])\n",
        "    return CHAINS[\"summary\"].invoke({\"text\": combined}).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ESTAT√çSTICAS DOS COMENT√ÅRIOS ANALISADOS\n",
        "# ============================================================\n",
        "\n",
        "def generate_stats(analyzed_comments):\n",
        "    \"\"\"\n",
        "    Calcula estat√≠sticas fundamentais (distribui√ß√µes)\n",
        "    para apoiar an√°lises quantitativas dos coment√°rios.\n",
        "\n",
        "    A fun√ß√£o recebe a lista de coment√°rios j√° enriquecidos\n",
        "    com sentimento, emo√ß√£o, contexto, idioma etc.,\n",
        "    e cria um DataFrame para gerar contagens de cada categoria.\n",
        "\n",
        "    Retorna um dicion√°rio estruturado contendo:\n",
        "        - sentiment_counts : distribui√ß√£o de positivo / neutro / negativo\n",
        "        - emotion_counts   : emo√ß√µes predominantes (alegria, nostalgia‚Ä¶)\n",
        "        - context_counts   : tipo de coment√°rio (m√∫sica, letra, pessoal‚Ä¶)\n",
        "        - language_counts  : idiomas encontrados\n",
        "    \"\"\"\n",
        "\n",
        "    # Criamos um DataFrame para facilitar opera√ß√µes tabulares\n",
        "    df = pd.DataFrame(analyzed_comments)\n",
        "\n",
        "    # Constru√≠mos o dicion√°rio de estat√≠sticas,\n",
        "    # sempre verificando se a coluna existe no DataFrame.\n",
        "    stats = {\n",
        "        \"sentiment_counts\": df[\"sentiment\"].value_counts().to_dict() \n",
        "            if \"sentiment\" in df else {},\n",
        "\n",
        "        \"emotion_counts\": df[\"emotion\"].value_counts().to_dict() \n",
        "            if \"emotion\" in df else {},\n",
        "\n",
        "        \"context_counts\": df[\"context\"].value_counts().to_dict() \n",
        "            if \"context\" in df else {},\n",
        "\n",
        "        \"language_counts\": df[\"language\"].value_counts().to_dict() \n",
        "            if \"language\" in df else {}\n",
        "    }\n",
        "\n",
        "    # Retornamos apenas o dicion√°rio;\n",
        "    # salvar em disco √© responsabilidade de outra fun√ß√£o.\n",
        "    return stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FUN√á√ïES DE SALVAMENTO DE ARQUIVOS\n",
        "# ============================================================\n",
        "\n",
        "def save_json(filename, data):\n",
        "    \"\"\"\n",
        "    Salva qualquer estrutura Python (dict, list, etc.)\n",
        "    em formato JSON com indenta√ß√£o e UTF-8 preservado.\n",
        "    \"\"\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SALVAMENTO ORGANIZADO POR V√çDEO\n",
        "# ============================================================\n",
        "\n",
        "def save_outputs_for_video(video_id, comments, analyzed, resumo, stats):\n",
        "    \"\"\"\n",
        "    Salva todos os arquivos essenciais gerados durante o processamento\n",
        "    de um v√≠deo espec√≠fico. A estrutura criada segue o padr√£o:\n",
        "\n",
        "        youtube_comments/\n",
        "            ‚îî‚îÄ‚îÄ <video_id>/\n",
        "                ‚îú‚îÄ‚îÄ comentarios_youtube_<video_id>.json\n",
        "                ‚îú‚îÄ‚îÄ comentarios_analisados_<video_id>.json\n",
        "                ‚îî‚îÄ‚îÄ stats_resumo_<video_id>.json\n",
        "\n",
        "    O objetivo √© manter tudo bem organizado e agrupado por v√≠deo,\n",
        "    facilitando futuras consultas, auditorias ou reprocessamentos.\n",
        "    \"\"\"\n",
        "\n",
        "    # Cria a pasta do v√≠deo se ainda n√£o existir\n",
        "    base_dir = f\"youtube_comments/{video_id}\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    # 1) Coment√°rios brutos coletados da API\n",
        "    # ----------------------------------------------\n",
        "    save_json(\n",
        "        f\"{base_dir}/comentarios_youtube_{video_id}.json\",\n",
        "        comments\n",
        "    )\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    # 2) Coment√°rios analisados (com tradu√ß√µes,\n",
        "    #    sentimentos, emo√ß√µes, contexto etc.)\n",
        "    # ----------------------------------------------\n",
        "    save_json(\n",
        "        f\"{base_dir}/comentarios_analisados_{video_id}.json\",\n",
        "        analyzed\n",
        "    )\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    # 3) Estat√≠sticas agregadas do v√≠deo\n",
        "    # ----------------------------------------------\n",
        "    save_json(\n",
        "        f\"{base_dir}/stats_resumo_{video_id}.json\",\n",
        "        stats\n",
        "    )\n",
        "\n",
        "    # Estat√≠sticas (mant√©m JSON)\n",
        "    with open(f\"{base_dir}/stats_resumo_{video_id}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(stats, f, indent=4, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_pdf_report(video_id, resumo, stats, analyzed, order_used):\n",
        "    \"\"\"\n",
        "    Gera um relat√≥rio PDF completo consolidando:\n",
        "        - Thumbnail do v√≠deo\n",
        "        - Link direto para o YouTube\n",
        "        - Ordem de coleta dos coment√°rios\n",
        "        - Resumo geral da an√°lise\n",
        "        - Estat√≠sticas (sentimento, emo√ß√£o, contexto, idioma)\n",
        "        - Wordcloud de palavras-chave\n",
        "        - Gr√°fico de distribui√ß√£o de contextos\n",
        "        - Lista completa de coment√°rios analisados\n",
        "\n",
        "    O objetivo √© criar um documento final de alta qualidade,\n",
        "    organizado visualmente e informativamente.\n",
        "    \"\"\"\n",
        "\n",
        "    base_dir = f\"youtube_comments/{video_id}\"\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "    file_path = f\"{base_dir}/relatorio_{video_id}.pdf\"\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # CONFIGURA√á√ÉO DO DOCUMENTO PDF\n",
        "    # ------------------------------------------------------------\n",
        "    doc = SimpleDocTemplate(\n",
        "        file_path,\n",
        "        pagesize=A4,\n",
        "        leftMargin=40, rightMargin=40,\n",
        "        topMargin=40, bottomMargin=40,\n",
        "        title=f\"Relat√≥rio de An√°lise - {video_id}\",\n",
        "    )\n",
        "\n",
        "    styles = getSampleStyleSheet()\n",
        "    story = []  # lista de blocos que comp√µem o PDF\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 1 ‚Äî CAPA / THUMBNAIL DO V√çDEO\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\"<b>Capa do V√≠deo</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 6))\n",
        "\n",
        "    thumb_path = f\"{base_dir}/thumbnail_{video_id}.jpg\"\n",
        "    thumb_urls = [\n",
        "        f\"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg\",\n",
        "        f\"https://img.youtube.com/vi/{video_id}/hqdefault.jpg\",\n",
        "    ]\n",
        "\n",
        "    # Tenta baixar a melhor thumbnail dispon√≠vel\n",
        "    downloaded = False\n",
        "    for url in thumb_urls:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=10)\n",
        "            if r.status_code == 200 and len(r.content) > 1000:\n",
        "                with open(thumb_path, \"wb\") as img:\n",
        "                    img.write(r.content)\n",
        "                downloaded = True\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if downloaded:\n",
        "        try:\n",
        "            img = Image(thumb_path)\n",
        "            img._restrictSize(450, 250)  # Limita tamanho no PDF\n",
        "            story.append(img)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö† Erro ao inserir thumbnail no PDF: {e}\")\n",
        "            story.append(Paragraph(\"<i>Thumbnail indispon√≠vel</i>\", styles[\"BodyText\"]))\n",
        "    else:\n",
        "        story.append(Paragraph(\"<i>Thumbnail n√£o encontrada</i>\", styles[\"BodyText\"]))\n",
        "\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 2 ‚Äî T√çTULO, LINK DO V√çDEO E ORDEM DE COLETA\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\n",
        "        f\"<b>Relat√≥rio de An√°lise de Coment√°rios ‚Äì V√≠deo {video_id}</b>\",\n",
        "        styles[\"Title\"]\n",
        "    ))\n",
        "    story.append(Spacer(1, 12))\n",
        "\n",
        "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    story.append(Paragraph(f'<a href=\"{video_url}\">{video_url}</a>', styles[\"BodyText\"]))\n",
        "    story.append(Spacer(1, 8))\n",
        "\n",
        "    story.append(Paragraph(\n",
        "        f\"<i>Ordem de coleta dos coment√°rios: <b>{order_used}</b></i>\",\n",
        "        styles[\"BodyText\"]\n",
        "    ))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 3 ‚Äî RESUMO GERAL DA AN√ÅLISE\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\"<b>Resumo Geral</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 6))\n",
        "    story.append(Paragraph(resumo, styles[\"BodyText\"]))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 4 ‚Äî TABELA DE ESTAT√çSTICAS\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\"<b>Estat√≠sticas de Coment√°rios</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 8))\n",
        "\n",
        "    def fmt_counts(d):\n",
        "        \"\"\"Formata dicion√°rios em texto leg√≠vel.\"\"\"\n",
        "        return \"‚Äî\" if not d else \", \".join([f\"{k}: {v}\" for k, v in d.items()])\n",
        "\n",
        "    stats_table = [\n",
        "        [\"M√©trica\", \"Distribui√ß√£o\"],\n",
        "        [\"Sentimentos\", fmt_counts(stats.get(\"sentiment_counts\", {}))],\n",
        "        [\"Emo√ß√µes\", fmt_counts(stats.get(\"emotion_counts\", {}))],\n",
        "        [\"Contextos\", fmt_counts(stats.get(\"context_counts\", {}))],\n",
        "        [\"Idiomas\", fmt_counts(stats.get(\"language_counts\", {}))],\n",
        "    ]\n",
        "\n",
        "    table = Table(stats_table, colWidths=[130, 350])\n",
        "    table.setStyle(TableStyle([\n",
        "        (\"BACKGROUND\", (0, 0), (-1, 0), colors.HexColor(\"#4B5563\")),\n",
        "        (\"TEXTCOLOR\", (0, 0), (-1, 0), colors.white),\n",
        "        (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
        "        (\"ALIGN\", (0, 0), (-1, -1), \"LEFT\"),\n",
        "        (\"BACKGROUND\", (0, 1), (-1, -1), colors.whitesmoke),\n",
        "        (\"GRID\", (0, 0), (-1, -1), 0.25, colors.black),\n",
        "    ]))\n",
        "\n",
        "    story.append(table)\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 5 ‚Äî WORDCLOUD (NUVEM DE PALAVRAS)\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\"<b>Nuvem de Palavras (Keywords)</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 6))\n",
        "\n",
        "    all_keywords = []\n",
        "    for c in analyzed:\n",
        "        if c.get(\"keywords\"):\n",
        "            all_keywords.extend([kw.strip() for kw in c[\"keywords\"].split(\",\")])\n",
        "\n",
        "    wc_text = \" \".join(all_keywords) if all_keywords else \"vazio\"\n",
        "\n",
        "    wc = WordCloud(width=800, height=400, background_color=\"white\").generate(wc_text)\n",
        "    wc_path = f\"{base_dir}/wordcloud_{video_id}.png\"\n",
        "    wc.to_file(wc_path)\n",
        "\n",
        "    story.append(Image(wc_path, width=400, height=200))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 6 ‚Äî GR√ÅFICO DE CONTEXTO\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\"<b>Distribui√ß√£o de Contextos</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 6))\n",
        "\n",
        "    context_counts = stats.get(\"context_counts\", {})\n",
        "\n",
        "    plt.figure(figsize=(6, 3))\n",
        "    plt.bar(context_counts.keys(), context_counts.values())\n",
        "    plt.title(\"Contextos dos Coment√°rios\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    ctx_path = f\"{base_dir}/context_chart_{video_id}.png\"\n",
        "    plt.savefig(ctx_path)\n",
        "    plt.close()\n",
        "\n",
        "    story.append(Image(ctx_path, width=400, height=200))\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 7 ‚Äî LISTA COMPLETA DE COMENT√ÅRIOS ANALISADOS\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\"<b>Lista Completa de Coment√°rios</b>\", styles[\"Heading2\"]))\n",
        "    story.append(Spacer(1, 10))\n",
        "\n",
        "    for idx, c in enumerate(analyzed, start=1):\n",
        "        text = c.get(\"translated\") or c.get(\"text\") or \"\"\n",
        "        lang = c.get(\"language\", \"\")\n",
        "\n",
        "        block = (\n",
        "            f\"<b>{idx}.</b> \"\n",
        "            f\"{f'[{lang}] ' if lang else ''}{text}\"\n",
        "            f\"<br/><i>Sentimento:</i> {c.get('sentiment', '‚Äî')} | \"\n",
        "            f\"<i>Emo√ß√£o:</i> {c.get('emotion', '‚Äî')} | \"\n",
        "            f\"<i>Contexto:</i> {c.get('context', '‚Äî')}\"\n",
        "        )\n",
        "\n",
        "        story.append(Paragraph(block, styles[\"BodyText\"]))\n",
        "        story.append(Spacer(1, 6))\n",
        "\n",
        "    story.append(Spacer(1, 20))\n",
        "\n",
        "    # ============================================================\n",
        "    # SE√á√ÉO 8 ‚Äî RODAP√â\n",
        "    # ============================================================\n",
        "    story.append(Paragraph(\n",
        "        f\"<i>Total de coment√°rios analisados: {len(analyzed)}</i>\",\n",
        "        styles[\"BodyText\"]\n",
        "    ))\n",
        "    story.append(Spacer(1, 6))\n",
        "\n",
        "    story.append(Paragraph(\n",
        "        f\"<i>Relat√≥rio gerado em {datetime.now().strftime('%d/%m/%Y %H:%M')}</i>\",\n",
        "        styles[\"BodyText\"]\n",
        "    ))\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # FINALIZA O PDF\n",
        "    # ------------------------------------------------------------\n",
        "    doc.build(story)\n",
        "    print(f\"üìÑ PDF gerado com sucesso: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# EXECU√á√ÉO PRINCIPAL\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import time\n",
        "\n",
        "    # Lista de v√≠deos que ser√£o analisados\n",
        "    VIDEO_IDS = [\n",
        "        \"ZpUYjpKg9KY\",  # Exemplo: Raimundos - Quero ver o Oco\n",
        "        \"3IcyRLeZDIs\",\n",
        "        # \"TAqZb52sgpU\",\n",
        "        # \"AkFqg5wAuFk\",\n",
        "    ]\n",
        "\n",
        "    print(\"\\n===============================================\")\n",
        "    print(\" INICIANDO PROCESSAMENTO DOS V√çDEOS DO YOUTUBE \")\n",
        "    print(\"===============================================\\n\")\n",
        "\n",
        "    for vid in VIDEO_IDS:\n",
        "        inicio_video = time.time()\n",
        "        print(f\"Iniciando processamento do v√≠deo: {vid}\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "\n",
        "        try:\n",
        "            # ------------------------------------------------------------\n",
        "            # 1) COLETA DE COMENT√ÅRIOS\n",
        "            # ------------------------------------------------------------\n",
        "            comments, order_used = extract_youtube_comments(\n",
        "                vid,\n",
        "                max_comments=30\n",
        "            )\n",
        "            print(f\"Coment√°rios coletados: {len(comments)}\")\n",
        "\n",
        "            # Se n√£o houver coment√°rios, ignora o v√≠deo\n",
        "            if len(comments) == 0:\n",
        "                print(\"Nenhum coment√°rio encontrado. Prosseguindo para o pr√≥ximo v√≠deo.\")\n",
        "                continue\n",
        "\n",
        "            # ------------------------------------------------------------\n",
        "            # 2) AN√ÅLISE DOS COMENT√ÅRIOS\n",
        "            # ------------------------------------------------------------\n",
        "            analyzed = analyze_comments(comments)\n",
        "            print(\"An√°lise conclu√≠da.\")\n",
        "\n",
        "            # ------------------------------------------------------------\n",
        "            # 3) GERA√á√ÉO DO RESUMO GERAL\n",
        "            # ------------------------------------------------------------\n",
        "            resumo = generate_final_summary(analyzed)\n",
        "            print(\"Resumo geral gerado.\")\n",
        "\n",
        "            # ------------------------------------------------------------\n",
        "            # 4) C√ÅLCULO DAS ESTAT√çSTICAS\n",
        "            # ------------------------------------------------------------\n",
        "            stats = generate_stats(analyzed)\n",
        "            print(\"Estat√≠sticas calculadas.\")\n",
        "\n",
        "            # ------------------------------------------------------------\n",
        "            # 5) SALVAMENTO DOS RESULTADOS EM ARQUIVOS\n",
        "            # ------------------------------------------------------------\n",
        "            save_outputs_for_video(\n",
        "                video_id=vid,\n",
        "                comments=comments,\n",
        "                analyzed=analyzed,\n",
        "                resumo=resumo,\n",
        "                stats=stats\n",
        "            )\n",
        "            print(\"Arquivos JSON salvos.\")\n",
        "\n",
        "            # ------------------------------------------------------------\n",
        "            # 6) GERA√á√ÉO DO RELAT√ìRIO PDF CONSOLIDADO\n",
        "            # ------------------------------------------------------------\n",
        "            generate_pdf_report(\n",
        "                video_id=vid,\n",
        "                resumo=resumo,\n",
        "                stats=stats,\n",
        "                analyzed=analyzed,\n",
        "                order_used=order_used\n",
        "            )\n",
        "            print(\"Relat√≥rio PDF gerado com sucesso.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar o v√≠deo {vid}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Tempo total do v√≠deo\n",
        "        fim_video = time.time()\n",
        "        print(f\"Tempo total: {fim_video - inicio_video:.2f} segundos\")\n",
        "        print(f\"Finalizado: youtube_comments/{vid}\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "\n",
        "    print(\"\\nProcessamento conclu√≠do para todos os v√≠deos.\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
